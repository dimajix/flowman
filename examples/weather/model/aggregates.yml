relations:
  aggregates:
    kind: file
    # Specify the file format to use
    format: parquet
    # Specify the base directory where all data is stored. This location does not include the partition pattern
    location: "$basedir/aggregates/"
    # You could specify the pattern how to identify files and/or partitions. This pattern is relative to the `location`.
    # Actually, it is highly recommended NOT to explicitly specify a partition pattern for outgoing relations
    # and let Spark generate this according to the Hive standard.
    #pattern: "${year}"
    # Add partition column, which can be used in the `pattern`
    partitions:
      - name: year
        type: integer
        granularity: 1
    # Specify an optional schema here. It is always recommended to explicitly specify a schema for every relation
    # and not just let data flow from a mapping into a target.
    schema:
      kind: embedded
      fields:
        - name: country
          type: STRING
        - name: min_wind_speed
          type: FLOAT
        - name: max_wind_speed
          type: FLOAT
        - name: avg_wind_speed
          type: FLOAT
        - name: min_temperature
          type: FLOAT
        - name: max_temperature
          type: FLOAT
        - name: avg_temperature
          type: FLOAT
